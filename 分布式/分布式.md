## 分布式

### 限流

#### 令牌桶算法

使用令牌桶算法。实现：guava（gua va）的RateLimiter

① 我们需要使用一个线程**以固定的速度向令牌桶（队列）里源源不断的放入令牌**

② 当我们请求来的时候，我们需要**先向令牌桶中获取一个令牌，拿到的令牌再执行请求，如果拿不到，就拒绝请求**

它的核心是令牌桶的令牌是有限的，如果桶满了，就不会再向桶里放入令牌。如果在一段时间内，请求的速度大于令牌的放入的速度，那么桶里面很快就没有令牌了，这样服务器就会拒绝一部分请求，从而达到服务降级的目的。

每秒1000次（CIR），可以通过配置更改，但是每秒钟需要往桶里加的令牌总数，并不是一次性加完的，一次性加进的令牌数量被称为Burst size（Bc）。如果Bc只是CIR的一半，那么很明显每秒钟就需要往桶里加两次令牌，每次加的数量总是Bc的数量。还有就是加令牌的时间，Time interval（Tc），

Tc表示多久该往桶里加一次令牌，而这个时间并不能手工设置，因为这个时间可以靠CIR和Bc的关系计算得到， Bc/ CIR= Tc。

桶的容量

<img src="https://cdn.jsdelivr.net/gh/jbz9/picture@main/image/16528557451791652855744331.png" style="zoom:50%;" />

### 缓存一致性

参考：http://kaito-kidd.com/2021/09/08/how-to-keep-cache-and-consistency-of-db/

#### 方案：读写分离

**写请求：**

写请求直接写入数据库，并且更新缓存。但是需要确认数据库和哪个先更新，会导致缓存不一致

**读请求：**

读请求先查询缓存，如果查不到，则从数据库读取，并重建缓存



![17018756012221701875600489.png](https://fastly.jsdelivr.net/gh/jbz9/picture@main/image/17018756012221701875600489.png)

#### 顺序问题

写请求直接写入数据库，并且更新缓存，因为更新分为2部分，所以有2种方案，并且存在「第一部分成功、第二部分失败」的问题。

**1、先更新数据库，后更新缓存**

**优点：**

- **避免缓存雪崩：** 缓存的失效和更新是原子操作，不会在更新期间导致大量读请求直接落到数据库。

**缺点：**

* **一致性问题**：** 如果缓存更新成功了，但数据库更新失败，那么此时缓存中是最新值，但数据库中是「旧值」。虽然此时读请求可以命中缓存，拿到正确的值，但是，**一旦缓存「失效」，就会从数据库中读取到「旧值」，重建缓存也是这个旧值。**

- **写延迟可能增加：** 由于写请求需要等待数据库更新完成，可能增加写请求的延迟。
- **读性能相对较低：** 读请求需要等待数据库更新完成后，才能从缓存中获取最新数据，相对较低的读性能。

**2、先更新缓存，后更新数据库**

**优点：**

- **提高读性能：** 读请求先从缓存中获取数据，可以提高读性能，降低对数据库的压力。
- **降低写延迟：** 由于缓存的更新是异步的，不会阻塞写请求，可以降低写请求的延迟。

**缺点：**

- **一致性问题：** 如果在更新缓存后数据库更新失败，那么此时数据库中是最新值，缓存中是「旧值」。之后的读请求读到的都是旧数据，只有当缓存「失效」后，才能从数据库中得到正确的值。这时用户会发现，自己刚刚修改了数据，但却看不到变更，一段时间过后，数据才变更过来，对业务也会有影响。
- **缓存雪崩：** 如果在缓存更新期间大量读请求落到缓存失效的情况下，可能导致缓存雪崩。

#### 并发问题

**1、先更新数据库，后更新缓存**

问题描述：

有线程 A 和线程 B 两个线程，需要更新「同一条」数据，会发生这样的场景：

1. 线程 A 更新数据库（X = A）
2. 线程 B 更新数据库（X = B）
3. 线程 B 更新缓存（X = B）
4. 线程 A 更新缓存（X = A）

最终缓存中值是 A，在数据库中是 B，发生不一致。操作顺序A-B-B-A

问题原因：线程A更新缓存慢了

![](https://cdn.jsdelivr.net/gh/jbz9/picture@main/image/16528703739771652870373817.png)

**2、先更新缓存，后更新数据库**

问题描述：

有线程 A 和线程 B 两个线程，需要更新「同一条」数据，会发生这样的场景：

1. 线程 A 更新缓存（X = A）
2. 线程 B缓存（X = B）
3. 线程 B 更新数据库（X = B）
4. 线程 A 更新数据库（X = A）

最终缓存中值是 B，在数据库中是 A，发生不一致。操作顺序A-B-B-A

#### 解决方案

为了并发情况下，导致的的一致性问题

##### 分布式锁（不推荐）

两个线程要修改「同一条」数据，每个线程在改之前，先去申请分布式锁，拿到锁的线程才允许更新数据库和缓存，拿不到锁的线程，返回失败，等待下次重试。

原因：缓存利用率不高、带来额外的性能开销、

##### 删除缓存（推荐）

删除缓存对应的方案也有 2 种：先删除缓存，后更新数据库；先更新数据库，后删除缓存

**1、先删除缓存，后更新数据库（不推荐）**

如果有 2 个线程要并发「读写」数据，可能会发生以下场景：

1. 线程 A 要更新 X = A（原值 X = B），线程 A 先删除缓存
2. 线程 B 读缓存，发现不存在，从数据库中读取到旧值（X = B）
3. 线程 A 将新值写入数据库（X = A）
4. 线程 B 将旧值写入缓存（X = B）

最终 X 的值在缓存中是 B（旧值），在数据库中是 A（新值），发生不一致。**可见，先删除缓存，后更新数据库，当发生「读+写」并发时，还是存在数据不一致的情况。**

![](https://fastly.jsdelivr.net/gh/jbz9/picture@main/image/16540587829701654058782219.png)

**2、先更新数据库，后删除缓存（推荐）**

如果有 2 个线程要并发「读写」数据，可能会发生以下场景：

1. 线程 **A 读**取数据库，得到旧值（X = A）
2. 线程 **B 更新**数据库（X = B)
3. 线程 B 删除缓存
4. 线程 A 将旧值写入缓存（X = A）

最终 X 的值在缓存中是 A（旧值），在数据库中是 B（新值），也发生不一致。操作顺序A-B-B-A。

这种情况「理论」来说是可能发生的，但实际真的有可能发生吗？其实概率「很低」，这是因为它必须满足 3 个条件：

1. 缓存刚好已失效
2. 读请求 + 写请求并发
3. 更新数据库 + 删除缓存的时间（步骤 3-4），要比读数据库 + 写缓存时间短（步骤 2 和 5），**即写比读快**

仔细想一下，条件 3 发生的概率其实是非常低的。**因为写数据库一般会先「加锁」，所以写数据库，通常是要比读数据库的时间更长的。**

###### 最终方案：先更新库，再删除缓存+延迟双删 

1. **写入数据：**
   - 当有写操作发生时，首先更新数据库（写库）。
   - 然后，立即删除缓存中对应的数据。
2. **读取数据：**
   - 当有读操作发生时，先尝试从缓存中读取数据。
   - 如果缓存中不存在数据（缓存未命中），再从数据库中读取数据。
   - 读取到数据后，将数据放入缓存，以便下次读取时能够直接命中缓存。
3. **延迟双删（Double-Delete）：**
   - 在写入数据库后，不立即删除缓存，而是延迟删除。
   - 在一定时间后，再次尝试删除缓存。这是为了确保在缓存中的数据在数据库更新后被删除，避免读取到脏数据。

![](https://fastly.jsdelivr.net/gh/jbz9/picture@main/image/16540592159701654059215257.png)



##### Binlog 

### 分布式事务

单点数据库事务：可用数据库隔离级别来解决

分布式情景下，会有多个数据库，导致了分布式事务的问题

解决方案：

开源方案：[seata/seata: Seata is an easy-to-use, high-performance, open source distributed transaction solution. (github.com)](https://github.com/seata/seata)

#### 两阶段规范

[分布式事务，这一篇就够了 | 小米信息部技术团队 (xiaomi-info.github.io)](https://xiaomi-info.github.io/2020/01/02/distributed-transaction/)

**分为2阶段，准备阶段和提交阶段，增加一个事务的协调者**

① 首先各个分布式服务（RM），做自己的独立操作，但是不提交

② 独立操作完成之后，发送一条消息通知事务协调者（TM）

③ 事务协调者确认所有的服务准备好了之后，再发消息告诉各个服务，可以进行commit操作了

④ 各个服务受到通知后，再进行本地的一个commit操作

存在的问题：

①同步阻塞：各个服务执行了sql，但是没有commit，它会占用数据库连接资源

②单点故障：协调者一旦出现故障，可能会导致各个服务一直处于阻塞状态

③网络问题导致的数据不一致：协调者通知服务进行commit的时候，有部分没有收到

④不确定性：

TM：事务管理器

RM：资源管理器

ApplicationProgram：应用程序

<img src="https://fastly.jsdelivr.net/gh/jbz9/picture@main/image/1654064501822%E5%88%86%E5%B8%83%E5%BC%8F-%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1-%E4%B8%A4%E9%98%B6%E6%AE%B5%E6%8F%90%E4%BA%A4.drawio.png" style="zoom:67%;" />

#### TCC

使用TCC补偿机制，就是Try Confirm Cancel。 主要分为三个阶段：

①Try阶段 ：主要是完成业务的一致性检查，并且预留资源。

②Confirm阶段：确认执行业务，try通过，默认Confirm成功，如果不成功，进行补差

③cancel阶段：取消执行，执行和try阶段相反的一个回滚操作

**优点**

相对于二阶段提交,解决它的了几个缺点:

①解决了协调者单点的问题

②引入超时，超时之后进行补偿，解决同步阻塞的问题，

③因为有了补偿机制，所以数据一致性得到解决。

**缺点**

①代码实现比较复杂，需要将一个业务接口拆分成try、confirm、cancel三个业务接口

#### 可靠消息最终一致性

**重点是通知机制**

##### 本地消息表

需要一张消息表和队列。假设有service服务

①serviceA做了一些本地数据库操作，做完之后需要向本地数据的消息表里写一条数据

②serviceA里面需要有一个后台任务去定时扫描消息表，向MQ发送消息，如果发送失败，就重试

③serviceB去消费MQ的消息，如果消费成功，那么就更新消息表中消息状态，因为serviceA的消息会重复发送，所以ServiceB实现接口的幂等性。

<img src="https://fastly.jsdelivr.net/gh/jbz9/picture@main/image/1654065158852%E5%88%86%E5%B8%83%E5%BC%8F-%E6%9C%AC%E5%9C%B0%E6%B6%88%E6%81%AF%E8%A1%A8.drawio.png" style="zoom:67%;" />

**使用消息队列的ACK机制确认消费成功**

（1）如何保证将消息发送给消息队列呢？

​	经过第一步消息已经写到消息日志表中，可以启动独立的线程，定时对消息日志表中的消息进行扫描并发送至消息中间件，在消息中间件反馈发送成功后删除该消息日志，否则等待定时任务下一周期重试。

（2）如何保证消费者一定能消费到消息呢？

这里可以使用MQ的ack（即消息确认）机制，消费者监听MQ，如果消费者接收到消息并且业务处理完成后向MQ发送ack（即消息确认），此时说明消费者正常消费消息完成，MQ将不再向消费者推送消息，否则消费者会不断重试向消费者来发送消息。	

##### RocketMQ

使用RocketMQ实现最终一致性。**需要使用Half Message 半消息和事务回查**

Half Message:

半消息

需要生产者commit之后才能被消息的消息。意思是，生产者发送半消息到rocketMQ服务器，它会被标记不能被投递，只有生产者进行commit操作后，才会进行投递，消息者才能进行消息。

事务回查

如果应该网络异常的原因，导致生产端一直没有对半消息进行commit确认，那么broker会主要向生产端确认事务执行的状态。

过程：

①服务A生产一条半消息到MQ

②MQ收到半消息之后确认投递成功

③然后服务A进行本地事务操作，完成后提交本地

④然后再提交半消息到MQ

⑤MQ收到半消息的提交之后，再投递消息

⑥ 服务B进行消费，并完成自己的本地事务

**服务A失败**

serviceA本地事务失败了，那么服务B的本地事务是不会执行的，因为half Msg 不会commit

**B服务失败怎么办？**

消息端可以重试，重试失败，那么需要把异常记录下来，由人工介入。

![](https://fastly.jsdelivr.net/gh/jbz9/picture@main/image/1654065349820%E5%88%86%E5%B8%83%E5%BC%8F-RocketMQ.drawio.png)

##### 最大努力通知

一直柔性事务解决方案，使用时间敏感性低的业务。

**方案一**

①服务A发送消息到MQ

②服务B消费消息，并返回消息状态

③如果没有消费成功，那么服务A会继续发送消息到MQ

问题：服务B直接监听MQ，只适合内部系统之间的消息通知

**方案二**

使用一个通知程序，服务B不再直接从MQ消费。

①服务A发送消息到MQ

②通知程序消费消息，并返回消息状态

③通知程序去通知服务B

问题：服务B直接监听MQ，只适合内部系统之间的消息通知

![](https://fastly.jsdelivr.net/gh/jbz9/picture@main/image/1654065586828%E5%88%86%E5%B8%83%E5%BC%8F-%E6%9C%80%E5%A4%A7%E5%8A%AA%E5%8A%9B%E9%80%9A%E7%9F%A5.drawio.png)

### 分布式锁

为什么需要使用分布式锁？

1. 系统是一个分布式系统，Java的锁已经锁不住了
2. 操作共享资源，比如库里唯一的用户数据
3. 同步访问，即多个进程同时操作共享资源

#### 基于redis

使用**setnx**命令，加锁的时候set key 过期时间 (时间单位是秒)和value，解锁的时候删除key。或者使用 set key value ex/px 过期时间 nx命令。 或者可以使用redisson库。

```shell
# 10s过期时间
setex k1 10 v1
```

##### **set、setex、setnx**

1**1、SET key value**

含义：

​     将字符串值 value 关联到 key 

​     如果 key 已经有值， 则覆写旧值，无视类型

**2、setex key seconds value**

该命令相当于将下面两行操作合并为一个[原子操作](https://so.csdn.net/so/search?q=原子操作&spm=1001.2101.3001.7020)

```bash
SET key value
EXPIRE key seconds  # 设置生存时间
```

含义（setex = set expire）：

​      将值 value 关联到 key ，并将 key 的生存时间设为 seconds (以秒为单位)。

​      如果 key 已经存在， SETEX 命令将覆写旧值。

**3、setnx key value**
含义（setnx = SET if Not eXists）：

```shell
将 key 的值设为 value ，当且仅当 key 不存在。

若给定的 key 已经存在，则 SETNX 不做任何动作。不能覆写

SETNX 是『SET if Not eXists』(如果不存在，则 SET的简写。
```
**set key value [EX seconds] [PX milliseconds] [NX|XX]**

从 Redis 2.6.12 版本开始， `SET` 命令的行为可以通过一系列参数来修改：

- `EX seconds` ： 将键的过期时间设置为 `seconds` 秒。 执行 `SET key value EX seconds` 的效果等同于执行 `SETEX key seconds value` 。
- `PX milliseconds` ： 将键的过期时间设置为 `milliseconds` 毫秒。 执行 `SET key value PX milliseconds` 的效果等同于执行 `PSETEX key milliseconds value` 。
- `NX` ： 只在键不存在时， 才对键进行设置操作。 执行 `SET key value NX` 的效果等同于执行 `SETNX key value` 。
- `XX` ： 只在键已经存在时， 才对键进行设置操作。

```shell

#设置 10s过期
SET 001 "hello" EX 10
#查看过期时间
ttl 001
#设置 毫秒过期
SET 001 "hello" px 1000000
```

使用 `NX` 选项：不能覆写，相当于setnx

```shell
redis> SET not-exists-key "value" NX
OK      # 键不存在，设置成功

redis> GET not-exists-key
"value"

redis> SET not-exists-key "new-value" NX
(nil)   # 键已经存在，设置失败

redis> GEt not-exists-key
"value" # 维持原值不变
```

使用 `XX` 选项：

```bash
redis> EXISTS exists-key
(integer) 0

redis> SET exists-key "value" XX
(nil)   # 因为键不存在，设置失败

redis> SET exists-key "value"
OK      # 先给键设置一个值

redis> SET exists-key "new-value" XX
OK      # 设置新值成功

redis> GET exists-key
"new-value"
```

#### 基于zookeeper

ZooKeeper 实现分布式锁的基本原理是基于其节点（ZNode）的**临时顺序节点和 Watcher 机制**。

```java
+-------------------------+
| 1. 创建锁的根节点        |
|    /distributed_lock     |
+-------------------------+
              |
              v
+-------------------------+
| 2. 进程A获取锁           |
|    a. 创建临时顺序节点   |
|       /distributed_lock/  |
|       lock_0001          |
|    b. 获取所有子节点列表  |
|       lock_0001, lock_0002, ... |
|    c. 判断自己节点是否最小 |
|       是: 进程A成功获取锁  |
|       否: 监听比自己小的节点的删除事件 |
+-------------------------+
              |
              v
+-------------------------+
| 3. 监听删除事件          |
|    a. 监听前一个节点的删除事件 |
|       (例如，监听lock_0000的删除事件) |
|    b. 一旦监听到比自己小的节点被删除，重复步骤2 |
+-------------------------+
              |
              v
+-------------------------+
| 4. 进程A执行业务逻辑     |
|    (执行业务逻辑的代码)   |
+-------------------------+
              |
              v
+-------------------------+
| 5. 进程A释放锁           |
|    a. 删除自己创建的节点  |
|       /distributed_lock/  |
|       lock_0001          |
+-------------------------+

```

### 分布式ID

#### 雪花算法

Snowflake 算法的核心思想是**使用一个 64 位的整数来表示一个唯一的 ID，其中包含了时间戳、机器 ID 和序列号**。

Snowflake 算法的 64 位结构如下：

```
Copy code
 1  |  41位的时间戳  |  10位的机器ID  |  12位的序列号
```

1. **时间戳（41位）：**
   - 用来表示 ID 生成的时间。由于使用的是毫秒级的时间戳，41 位的时间戳可以表示 2^41 毫秒，大约可以支持 69 年的时间。
2. **机器ID（10位）：**
   - 用来表示生成 ID 的机器的唯一标识。可以手动配置机器 ID，也可以动态获取。
3. **序列号（12位）：**
   - 在同一毫秒内，如果有多个 ID 被生成，使用序列号来区分。支持同一机器同一毫秒内生成 2^12 - 1 个不同的序列号。

```java
public class SnowflakeIdGenerator {

    // 起始的时间戳，2021-01-01 00:00:00
    private static final long START_TIMESTAMP = 1609459200000L;

    // 机器ID所占的位数
    private static final long MACHINE_ID_BITS = 10L;

    // 序列号所占的位数
    private static final long SEQUENCE_BITS = 12L;

    // 支持的最大机器ID，结果是1023
    private static final long MAX_MACHINE_ID = -1L ^ (-1L << MACHINE_ID_BITS);

    // 支持的最大序列号，结果是4095
    private static final long MAX_SEQUENCE = -1L ^ (-1L << SEQUENCE_BITS);

    // 机器ID左移的位数，即序列号位数
    private static final long MACHINE_ID_SHIFT = SEQUENCE_BITS;

    // 时间戳左移的位数，即机器ID位数 + 序列号位数
    private static final long TIMESTAMP_SHIFT = MACHINE_ID_BITS + SEQUENCE_BITS;

    // 上一次生成ID的时间戳
    private long lastTimestamp = -1L;

    // 当前毫秒内已经生成的序列号
    private long sequence = 0L;

    // 机器ID
    private long machineId;

    public SnowflakeIdGenerator(long machineId) {
        if (machineId < 0 || machineId > MAX_MACHINE_ID) {
            throw new IllegalArgumentException("Machine ID must be between 0 and " + MAX_MACHINE_ID);
        }
        this.machineId = machineId;
    }

    public synchronized long generateId() {
        // 获取当前时间戳
        long currentTimestamp = System.currentTimeMillis();

        // 如果当前时间小于上一次ID生成的时间戳，说明系统时钟回退过，抛出异常
        if (currentTimestamp < lastTimestamp) {
            throw new RuntimeException("Clock moved backwards. Refusing to generate ID.");
        }

        // 如果是同一时间生成的，则进行毫秒内序列号递增
        if (currentTimestamp == lastTimestamp) {
            sequence = (sequence + 1) & MAX_SEQUENCE;
            // 毫秒内序列号溢出，等待下一毫秒
            if (sequence == 0) {
                currentTimestamp = waitUntilNextMillis(currentTimestamp);
            }
        } else {
            // 时间戳改变，毫秒内序列号重置
            sequence = 0L;
        }

        // 更新上一次ID生成的时间戳
        lastTimestamp = currentTimestamp;

        // 构造ID：时间戳部分（41位） | 机器ID部分（10位） | 序列号部分（12位）
        return ((currentTimestamp - START_TIMESTAMP) << TIMESTAMP_SHIFT)
                | (machineId << MACHINE_ID_SHIFT)
                | sequence;
    }

    private long waitUntilNextMillis(long currentTimestamp) {
        long timestamp = System.currentTimeMillis();
        while (timestamp <= currentTimestamp) {
            timestamp = System.currentTimeMillis();
        }
        return timestamp;
    }

    public static void main(String[] args) {
        // 机器ID，可根据实际情况配置
        long machineId = 1L;

        SnowflakeIdGenerator idGenerator = new SnowflakeIdGenerator(machineId);

        // 生成10个ID并打印
        for (int i = 0; i < 10; i++) {
            long id = idGenerator.generateId();
            System.out.println(id);
        }
    }
}

```

#### Tracking ID

全局唯一的 Tracking ID（追踪标识符）通常用于在**分布式系统中跟踪请求**或事件，以便能够**在系统的不同组件之间追溯和关联**。生成全局唯一的 Tracking ID 可以使用类似 UUID 或 Snowflake 算法的方法。



