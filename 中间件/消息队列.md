#### 简介

消息队列相当于一个存放消息的容器，当我们需要使用消息的时候，从队列中取出来就可以了，它（队列Queue）是一个先进先出的数据结构，比如生成者按照A、B、C的顺序发送消息到队列中，那么消费者就会按照A、B、C的顺序进行消费。

为什么使用消息队列？

一方面消除了生产者类与消费者类之间的代码依赖性，另一方面将生产数据的过程与使用数据的过程解耦简化负载。

* 提高系统性能：如果不使用队列，数据直接写入数据库，在高并发下的情况下，数据压力会变大，导致对用户的响应变慢，如果使用队列之后，用户数据发送到消息队列之后，立即可以得到返回，然后再由消费者队列异步将数据写入数据库
* 降低系统的耦合性，消息队列通过发布-订阅模式（一个消息生产者，多个消息消费者），消息生成者将消息发送到队列，消息消费者从队列获取消费，等于在消息者之间加了一个中间层，使得生产者和消费者之间没有直接耦合

缺点：

* 增加了系统的复杂度
* 数据一致性问题：消费者可能没有拿到正确的消息

什么是JMS

JMS（JAVA Message Service,java消息服务）是java的消息服务

#### 消息模型

* 点对点：一对一，一个生产者对应一个消费者
* 发布-订阅：一对多，一个生产者生产的消息可以被多个消费者消费

#### 通讯模式   
共3种：单播、广播、组播  

一、单播

主机之间“一对一”的通讯模式，网络中的交换机和路由器对数据只进行转发不进行复制。

优点：

响应更加及时、服务器能够对每个主机都发送不同的数据，能够实现个性化服务。

缺点：

通讯成本高，

二、广播

主机之间“一对所有”的通讯模式，网络对其中每一台主机发出的信号都进行无条件复制并转发。

优点：

通讯成本低

缺点：

无法实现个性化服务。

三、组播

主机之间“一对一组”，即同一组的主机可以接受到同样的数据

#### Kafka

https://kafka.apachecn.org/documentation.html#design

是一个**分布式发布-订阅**消息队列。Kafka将消息保留在磁盘上，并在集群内复制以防止数据丢失。生产者往队列里写消息，消费者往队列里取消息，起到解耦、削峰异步处理的作用。

Kafka基于文件存储，当文件大到一定程度时，很容易就达到了服务器的磁盘空间，因此，Kafka采用了分区的方式，一个分区对应一个文件，这样就可以将数据存到不同的节点上去，做到负载均衡。

kafka中的概念

* broker：集群中的节点，**broker**接受来自生产者的消息，为消息设置偏移量，并提交消息到磁盘保存
* top：主题，是对存到kafka中消息的分类，一个top中保存的是一类消息，每个生产者在将消息存储到队列中时，都需要指定top
* 分区：一个top对应多个分区partition，每个partition在存储层面上都是append log 文件。同一个主题中的分区可以不在一个机器上，有可能会部署在多个机器上，由此来实现 kafka 的`伸缩性`
* 偏移量：Offset，一个分区对应一个磁盘上的文件，而消息在文件中的位置就称为 offset（偏移量），offset 为一个 long 型数字，它可以唯一标记一条消息。由于kafka 并没有提供其他额外的索引机制来存储 offset，文件只能顺序的读写，所以在kafka中几乎不允许对消息进行“随机读写”。
* 每条记录中包含一个key，一个value和一个timestamp（时间戳）。

如何避免重复消费？

通过偏移量offset，每次











Topics和日志

Topic 就是数据主题，是数据记录发布的地方,可以用来区分业务系统。Kafka中的Topics总是多订阅者模式，一个topic可以拥有一个或者多个消费者来订阅它的数据。

对于每一个topic， Kafka集群都会维持一个分区日志，如下所示：

<img src="D:\软件\Markdown\typora-user-images\image-20201224155448589.png" alt="image-20201224155448589" style="zoom:50%;" />



每个分区都是有序且顺序不可变的记录集，并且不断地追加到结构化的commit log文件。分区中的每一个记录都会分配一个id号来表示顺序，**我们称之为offset（偏移量），*offset*用来唯一的标识分区中每一条记录。**

Kafka 集群保留所有发布的记录—无论他们是否已被消费—并通过一个可配置的参数——保留期限来控制. 举个例子， 如果保留策略设置为2天，一条记录发布后两天内，可以随时被消费，两天过后这条记录会被抛弃并释放磁盘空间。Kafka的性能和数据大小无关，所以长时间存储数据没有什么问题.

日志中的 partition（分区）有以下几个用途。第一，当日志大小超过了单台服务器的限制，允许日志进行扩展。每个单独的分区都必须受限于主机的文件限制，不过一个主题可能有多个分区，因此可以处理无限量的数据。

消费者：

每一个消费者都属于一个消费组 consumer group，订阅 Topic 是以一个消费组来订阅的，发送到 Topic 的消息，只会被订阅此 Topic 的每个 group 中的一个 consumer 消费。

Kafka consumer通过向 broker 发出一个“fetch”请求来获取它想要消费的 partition。consumer 的每个请求都在 log 中指定了对应的 offset，并接收从该位置开始的一大块数据。因此，consumer 对于该位置的控制就显得极为重要，并且可以在需要的时候通过回退到该位置再次消费对应的数据。

 在队列中，消费者池从server读取数据，每条记录被池子中的一个消费者消费; 在发布订阅中，记录被广播到所有的消费者。两者均有优缺点。 队列的优点在于它允许你将处理数据的过程分给多个消费者实例，使你可以扩展处理过程。 不好的是，队列不是多订阅者模式的—一旦一个进程读取了数据，数据就会被丢弃。 而发布-订阅系统允许你广播数据到多个进程，但是无法进行扩展处理，因为每条消息都会发送给所有的订阅者。

Push vs. pull

Kafka 在这方面采取了一种较为传统的设计方式，也是大多数的消息系统所共享的方式：即 producer 把数据 push 推到 broker，然后 consumer 从 broker 中 pull 拉数据。 

Replication

Kafka 允许 topic 的 partition 拥有若干副本，你可以在server端配置partition 的副本数量。当集群中的节点出现故障时，能自动进行故障转移，保证数据的可用性。

分区（Partition）中的多个副本之间会有一个叫做 leader 的家伙，其他副本称为 follower。我们发送的消息会被发送到 leader 副本，然后 follower 副本才能从 leader 副本中拉取消息进行同步。

**消费者分区分配策略**

架构模式：

![image-20210129103839990](D:\软件\Markdown\typora-user-images\image-20210129103839990.png)

#### RocketMQ

https://github.com/apache/rocketmq/tree/master/docs/cn

rocketmq是基于发布订阅模式的队列。consumer的消费进度是存储在broker上的，consumer本身不存储进度。好处是：当 consumer 集群是扩大或者缩小时，由于消费进度统一在broker上，消息重复的概率会被大大降低了。

概念

* 生产者producer：生产消息
* 消费者Consumer：消费消息

* broker：存储消息

RocketMQ提供多种发送方式：

- 同步发送

  同步发送就是指 producer 发送消息后，会在接收到 broker 响应后才继续发下一条消息的通信方式。由于这种同步发送的方式确保了消息的可靠性，同时也能及时得到消息发送的结果，故而适合一些发送比较重要的消息场景，比如说重要的通知邮件、营销短信等等。在实际应用中，这种同步发送的方式还是用得比较多的。

- 异步发送：

  异步发送是指 producer 发出一条消息后，不需要等待 broker 响应，就接着发送下一条消息的通信方式。需要注意的是，不等待 broker 响应，并不意味着 broker 不响应，而是通过回调接口来接收 broker 的响应。所以要记住一点，异步发送同样可以对消息的响应结果进行处理。

  由于异步发送不需要等待 broker 的响应，故在一些比较注重 RT（响应时间）的场景就会比较适用。比如，在一些视频上传的场景，我们知道视频上传之后需要进行转码，如果使用同步发送的方式来通知启动转码服务，那么就需要等待转码完成才能发回转码结果的响应，由于转码时间往往较长，很容易造成响应超时。此时，如果使用的是异步发送通知转码服务，那么就可以等转码完成后，再通过回调接口来接收转码结果的响应了。

- 单向发送：

  就是一种单方向通信方式，也就是说 producer 只负责发送消息，不等待 broker 发回响应结果，而且也没有回调函数触发，这也就意味着 producer 只发送请求不等待响应结果。

  由于单向发送只是简单地发送消息，不需要等待响应，也没有回调接口触发，故发送消息所耗费的时间非常短，同时也意味着消息不可靠。所以这种单向发送比较适用于那些耗时要求非常短，但对可靠性要求并不高的场景，比如说日志收集。

消费方式

* 集群消费：相同Consumer Group的每个Consumer实例平均分摊消息，消费者平摊消息
* 广播消费：相同Consumer Group的每个Consumer实例都接收全量的消息，每个消费者都会消费一遍消息

Consumer的负载均衡

在RocketMQ中，Consumer端的两种消费模式（Push/Pull）都是基于拉模式来获取消息的，而在Push模式只是对pull模式的一种封装，其本质实现为消息拉取线程在从服务器拉取到一批消息后，然后提交到消息消费线程池后，又“马不停蹄”的继续向服务器再次尝试拉取消息。如果未拉取到消息，则延迟一下又继续拉取。在两种基于拉模式的消费方式（Push/Pull）中，均需要Consumer端在知道从Broker端的哪一个消息队列—队列中去获取消息。因此，有必要在Consumer端来做负载均衡，即Broker端中多个MessageQueue分配给同一个ConsumerGroup中的哪些Consumer消费。

#### 消息队列对比

![image-20210414171758907](D:\软件\Markdown\typora-user-images\image-20210414171758907.png)

#### 消息队列的使用

##### docker安装rocketMq

```shell
docker run -d -p 9876:9876 -v /home/open/kafka/rocketmq-docker/data/namesrv/logs:/root/logs -v /home/open/kafka/rocketmq-docker/data/namesrv/store:/root/store --name rmqnamesrv -e "MAX_POSSIBLE_HEAP=100000000" rocketmqinc/rocketmq:4.4.0 sh mqnamesrv

docker run -d -p 10911:10911 -p 10909:10909 -v  /home/open/kafka/rocketmq-docker/data/broker/logs:/root/logs -v  /home/open/kafka/rocketmq-docker/data/broker/store:/root/store -v  /home/open/kafka/rocketmq-docker/conf/broker.conf:/opt/rocketmq-4.4.0/conf/broker.conf --name rmqbroker --link rmqnamesrv:namesrv -e "NAMESRV_ADDR=namesrv:9876" -e "MAX_POSSIBLE_HEAP=200000000" rocketmqinc/rocketmq:4.4.0 sh mqbroker -c /opt/rocketmq-4.4.0/conf/broker.conf

docker run -d --name rmqconsole -p 9800:8080 --link rmqnamesrv:namesrv -e "JAVA_OPTS=-Drocketmq.namesrv.addr=namesrv:9876 -Dcom.rocketmq.sendMessageWithVIPChannel=false" -t styletang/rocketmq-console-ng

docker start rmqnamesrv
docker start rmqbroker
docker start rmqbroker
http://192.168.52.190:9800
```



