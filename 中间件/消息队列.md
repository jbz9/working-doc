#### 简介

消息队列相当于一个存放消息的容器，当我们需要使用消息的时候，从队列中取出来就可以了，它（队列Queue）是一个先进先出的数据结构，比如生成者按照A、B、C的顺序发送消息到队列中，那么消费者就会按照A、B、C的顺序进行消费。

为什么使用消息队列？

一方面消除了生产者类与消费者类之间的代码依赖性，另一方面将生产数据的过程与使用数据的过程解耦简化负载。

* 提高系统性能：如果不使用队列，数据直接写入数据库，在高并发下的情况下，数据压力会变大，导致对用户的响应变慢，如果使用队列之后，用户数据发送到消息队列之后，立即可以得到返回，然后再由消费者队列异步将数据写入数据库
* 降低系统的耦合性，消息队列通过发布-订阅模式（一个消息生产者，多个消息消费者），消息生成者将消息发送到队列，消息消费者从队列获取消费，等于在消息者之间加了一个中间层，使得生产者和消费者之间没有直接耦合

缺点：

* 增加了系统的复杂度
* 数据一致性问题：消费者可能没有拿到正确的消息

什么是JMS

JMS（JAVA Message Service,java消息服务）是java的消息服务

#### 消息模型

* 点对点：一对一，一个生产者对应一个消费者
* 发布-订阅：一对多，一个生产者生产的消息可以被多个消费者消费

#### 通讯模式   
共3种：单播、广播、组播  

一、单播

主机之间“一对一”的通讯模式，网络中的交换机和路由器对数据只进行转发不进行复制。

优点：

响应更加及时、服务器能够对每个主机都发送不同的数据，能够实现个性化服务。

缺点：

通讯成本高，

二、广播

主机之间“一对所有”的通讯模式，网络对其中每一台主机发出的信号都进行无条件复制并转发。

优点：

通讯成本低

缺点：

无法实现个性化服务。

三、组播

主机之间“一对一组”，即同一组的主机可以接受到同样的数据

#### Kafka

https://kafka.apachecn.org/documentation.html#design

是一个**分布式发布-订阅**消息队列。Kafka将消息保留在磁盘上，并在集群内复制以防止数据丢失。生产者往队列里写消息，消费者往队列里取消息，起到解耦、削峰异步处理的作用。

Kafka基于文件存储，当文件大到一定程度时，很容易就达到了服务器的磁盘空间，因此，Kafka采用了分区的方式，一个分区对应一个文件，这样就可以将数据存到不同的节点上去，做到负载均衡。

kafka中的概念

* broker：集群中的节点，**broker**接受来自生产者的消息，为消息设置偏移量，并提交消息到磁盘保存
* top：主题，是对存到kafka中消息的分类，一个top中保存的是一类消息，每个生产者在将消息存储到队列中时，都需要指定top
* 分区：一个top对应多个分区partition，每个partition在存储层面上都是append log 文件。同一个主题中的分区可以不在一个机器上，有可能会部署在多个机器上，由此来实现 kafka 的`伸缩性`
* 偏移量：Offset，一个分区对应一个磁盘上的文件，而消息在文件中的位置就称为 offset（偏移量），offset 为一个 long 型数字，它可以唯一标记一条消息。由于kafka 并没有提供其他额外的索引机制来存储 offset，文件只能顺序的读写，所以在kafka中几乎不允许对消息进行“随机读写”。
* 每条记录中包含一个key，一个value和一个timestamp（时间戳）。

如何避免重复消费？

通过偏移量offset

Topics和日志

Topic 就是数据主题，是数据记录发布的地方,可以用来区分业务系统。Kafka中的Topics总是多订阅者模式，一个topic可以拥有一个或者多个消费者来订阅它的数据。

对于每一个topic， Kafka集群都会维持一个分区日志，如下所示：

<img src="D:\软件\Markdown\typora-user-images\image-20201224155448589.png" alt="image-20201224155448589" style="zoom:50%;" />



每个分区都是有序且顺序不可变的记录集，并且不断地追加到结构化的commit log文件。分区中的每一个记录都会分配一个id号来表示顺序，**我们称之为offset（偏移量），*offset*用来唯一的标识分区中每一条记录。**

Kafka 集群保留所有发布的记录—无论他们是否已被消费—并通过一个可配置的参数——保留期限来控制. 举个例子， 如果保留策略设置为2天，一条记录发布后两天内，可以随时被消费，两天过后这条记录会被抛弃并释放磁盘空间。Kafka的性能和数据大小无关，所以长时间存储数据没有什么问题.

日志中的 partition（分区）有以下几个用途。第一，当日志大小超过了单台服务器的限制，允许日志进行扩展。每个单独的分区都必须受限于主机的文件限制，不过一个主题可能有多个分区，因此可以处理无限量的数据。

消费者：

每一个消费者都属于一个消费组 consumer group，订阅 Topic 是以一个消费组来订阅的，发送到 Topic 的消息，只会被订阅此 Topic 的每个 group 中的一个 consumer 消费。

Kafka consumer通过向 broker 发出一个“fetch”请求来获取它想要消费的 partition。consumer 的每个请求都在 log 中指定了对应的 offset，并接收从该位置开始的一大块数据。因此，consumer 对于该位置的控制就显得极为重要，并且可以在需要的时候通过回退到该位置再次消费对应的数据。

 在队列中，消费者池从server读取数据，每条记录被池子中的一个消费者消费; 在发布订阅中，记录被广播到所有的消费者。两者均有优缺点。 队列的优点在于它允许你将处理数据的过程分给多个消费者实例，使你可以扩展处理过程。 不好的是，队列不是多订阅者模式的—一旦一个进程读取了数据，数据就会被丢弃。 而发布-订阅系统允许你广播数据到多个进程，但是无法进行扩展处理，因为每条消息都会发送给所有的订阅者。

Push vs. pull

Kafka 在这方面采取了一种较为传统的设计方式，也是大多数的消息系统所共享的方式：即 producer 把数据 push 推到 broker，然后 consumer 从 broker 中 pull 拉数据。 

Replication

Kafka 允许 topic 的 partition 拥有若干副本，你可以在server端配置partition 的副本数量。当集群中的节点出现故障时，能自动进行故障转移，保证数据的可用性。

分区（Partition）中的多个副本之间会有一个叫做 leader 的家伙，其他副本称为 follower。我们发送的消息会被发送到 leader 副本，然后 follower 副本才能从 leader 副本中拉取消息进行同步。

**消费者分区分配策略**

架构模式：

![image-20210129103839990](D:\软件\Markdown\typora-user-images\image-20210129103839990.png)

#### RocketMQ

https://github.com/apache/rocketmq/tree/master/docs/cn

rocketmq是基于发布订阅模式的队列。consumer的消费进度是存储在broker上的，consumer本身不存储进度。好处是：当 consumer 集群是扩大或者缩小时，由于消费进度统一在broker上，消息重复的概率会被大大降低了。

概念

* 生产者producer：生产消息
* 消费者Consumer：消费消息

* broker：存储消息

RocketMQ提供多种发送方式：

- 同步发送

  同步发送就是指 producer 发送消息后，会在接收到 broker 响应后才继续发下一条消息的通信方式。由于这种同步发送的方式确保了消息的可靠性，同时也能及时得到消息发送的结果，故而适合一些发送比较重要的消息场景，比如说重要的通知邮件、营销短信等等。在实际应用中，这种同步发送的方式还是用得比较多的。

- 异步发送：

  异步发送是指 producer 发出一条消息后，不需要等待 broker 响应，就接着发送下一条消息的通信方式。需要注意的是，不等待 broker 响应，并不意味着 broker 不响应，而是通过回调接口来接收 broker 的响应。所以要记住一点，异步发送同样可以对消息的响应结果进行处理。

  由于异步发送不需要等待 broker 的响应，故在一些比较注重 RT（响应时间）的场景就会比较适用。比如，在一些视频上传的场景，我们知道视频上传之后需要进行转码，如果使用同步发送的方式来通知启动转码服务，那么就需要等待转码完成才能发回转码结果的响应，由于转码时间往往较长，很容易造成响应超时。此时，如果使用的是异步发送通知转码服务，那么就可以等转码完成后，再通过回调接口来接收转码结果的响应了。

- 单向发送：

  就是一种单方向通信方式，也就是说 producer 只负责发送消息，不等待 broker 发回响应结果，而且也没有回调函数触发，这也就意味着 producer 只发送请求不等待响应结果。

  由于单向发送只是简单地发送消息，不需要等待响应，也没有回调接口触发，故发送消息所耗费的时间非常短，同时也意味着消息不可靠。所以这种单向发送比较适用于那些耗时要求非常短，但对可靠性要求并不高的场景，比如说日志收集。

消费方式

* 集群消费：相同Consumer Group的每个Consumer实例平均分摊消息，消费者平摊消息
* 广播消费：相同Consumer Group的每个Consumer实例都接收全量的消息，每个消费者都会消费一遍消息

Consumer的负载均衡

在RocketMQ中，Consumer端的两种消费模式（Push/Pull）都是基于拉模式来获取消息的，而在Push模式只是对pull模式的一种封装，其本质实现为消息拉取线程在从服务器拉取到一批消息后，然后提交到消息消费线程池后，又“马不停蹄”的继续向服务器再次尝试拉取消息。如果未拉取到消息，则延迟一下又继续拉取。在两种基于拉模式的消费方式（Push/Pull）中，均需要Consumer端在知道从Broker端的哪一个消息队列—队列中去获取消息。因此，有必要在Consumer端来做负载均衡，即Broker端中多个MessageQueue分配给同一个ConsumerGroup中的哪些Consumer消费。

#### 消息队列对比

![image-20210414171758907](D:\软件\Markdown\typora-user-images\image-20210414171758907.png)

#### 消息队列的使用

#### docker安装rocketMq

```shell
docker pull rocketmqinc/rocketmq:4.4.0

docker run -d -p 9876:9876 -v /e/develop/docker/repo/rocketmq/rocketmq-docker/data/namesrv/logs:/root/logs -v /e/develop/docker/repo/rocketmq/rocketmq-docker/data/namesrv/store:/root/store --name rmqnamesrv -e "MAX_POSSIBLE_HEAP=100000000" rocketmqinc/rocketmq:4.4.0 sh mqnamesrv

docker run -d -p 10911:10911 -p 10909:10909 -v  /e/develop/docker/repo/rocketmq-docker/data/broker/logs:/root/logs -v  /e/develop/docker/repo/rocketmq-docker/data/broker/store:/root/store -v /e/develop/docker/repo/rocketmq/rocketmq-docker/conf/broker.conf:/opt/rocketmq-4.4.0/conf/broker.conf --name rmqbroker --link rmqnamesrv:namesrv -e "NAMESRV_ADDR=namesrv:9876" -e "MAX_POSSIBLE_HEAP=200000000" rocketmqinc/rocketmq:4.4.0 sh mqbroker -c /opt/rocketmq-4.4.0/conf/broker.conf

docker run -d --name rmqconsole -p 9800:8080 --link rmqnamesrv:namesrv -e "JAVA_OPTS=-Drocketmq.namesrv.addr=namesrv:9876 -Dcom.rocketmq.sendMessageWithVIPChannel=false" -t styletang/rocketmq-console-ng

docker start rmqnamesrv
docker start rmqbroker
docker start rmqbroker
http://192.168.52.190:9800
```

#### 线上消息积压怎么处理

1、先找到消息积压的原因

2、如果只是消息过多，消费者能力不足，那么就需要对消费者进行扩容；

3、如果是消费端出现了问题，那么首先要先修复问题，同时把消息迁移到新队列，重新使用新的消费者对新队列进行进行消费，知道后缀问题修复了，再切回原先的队列。

#### 死信队列

消息设置了过期时间，但是在过期时间内没有被消费，那这个消息就是死信。使用，`x-dead-letter-exchange` 和 `x-dead-letter-routing-key` 参数设置私信队列的交换机和路由键

#### RabbtiMQ消息设置了过期时间，消息丢失了

消息过了过期时间，没有被消费，这些消息就是死信，如果没有配置死信队列（Dead Letter Queue）去消费，那么这些消息就是找不到了，在设置过期消息的时候，可以去配置死信队列

#### RabbitMQ设置过期时间的方式

1、设置队列属性`expiration` ，所有的消息设置为统一的过期时间

2、设置消息属性 `x-message-ttl` 

过期消息会被 RabbitMQ 自动删除。

##### 实例

1. **通过消息属性设置：** 在发送消息的时候，通过消息的属性设置过期时间。RabbitMQ 使用 `expiration` 属性表示消息的过期时间。

   ```
   javaCopy codeimport com.rabbitmq.client.AMQP;
   import com.rabbitmq.client.Channel;
   
   // 创建消息属性
   AMQP.BasicProperties properties = new AMQP.BasicProperties.Builder()
           .expiration("60000") // 设置过期时间，单位毫秒
           .build();
   
   // 发送带有过期时间的消息
   channel.basicPublish(exchange, routingKey, properties, messageBodyBytes);
   ```

   上述代码中，`expiration("60000")` 表示设置消息的过期时间为 60 秒。

2. **通过队列属性设置：** 在声明队列的时候，也可以通过 `x-message-ttl` 参数设置队列的默认过期时间。这样发送到该队列的所有消息都会继承该过期时间。

   ```
   javaCopy code// 声明队列并设置过期时间
   channel.queueDeclare(queueName, false, false, false, 
           ImmutableMap.of("x-message-ttl", 60000)); // 设置过期时间为 60 秒
   ```

   上述代码中，`x-message-ttl` 参数的值为过期时间，单位为毫秒。

#### 消息队列进行分布式部署

#### 项目是哪里用到了消息队列

主要是在日志模块使用到了消息队列，在接口调用方去调用接口的时候，我们会把接口调用信息，比如调用时间、调用状态、请求方式、报文，还有调用方、被调用方的信息这些包装成消息实体，然后异步发送到消息队列，消息的处理，我们有异步包，通过线程池的方式来启动消费者，去消费日志消息，然后把消息存入到ES，然后日志界面，通过查询ES来展示调用信息，主要起到一个异步、解耦的作用。

#### 如何保证消息不被重复消费

MQ本身的话无法做到不重复消息，需要在消费端自己去实现接口的一个幂等性。

需要**保证消费时的幂等性**，也是就是无论重复请求有多少次，消息端只消费一次。

如何保证幂等性：

**如果是写入数据库**：那么在写入数据的时候，可以用主键ID查一下，如果有数据就更新；或者的话数据库加一个唯一建约束，这样插入的时候，如果重复插入的话就会插入失败；

**如果是写入redis**，那么就不需要做额外的工作了，因为redis在set是支持幂等性的

#### 接口幂等性

幂等性是指同一个请求的多次执行，产生的效果和一次执行的效果相同。确保服务端接口的幂等性是为了防止重复请求带来的问题。

解决方案：

**使用唯一标识符：**

- **请求带唯一标识符**
  * 每个请求都应该携带一个唯一标识符，比如请求编号。服务端在处理请求之前，可以记录已经处理过的请求编号。如果相同的请求编号再次到达，服务端可以判断为重复请求，并直接返回之前的处理结果，而不再执行实际操作。
- **使用哈希算法**
  - 对请求参数进行哈希运算，将哈希值作为标识符。相同参数的请求将具有相同的哈希值，可以通过哈希值判断是否是重复请求。
- 如果是数据库的话，使用唯一索引或主键，来确保数据的唯一性
- **使用哈希算法**

#### 如何保证消息顺序消费

rocketMQ有顺序消息机制，它支持分区有序。

分区顺序：一个Partition内所有的消息按照先进先出的顺序进行发布和消费

全局顺序：一个Topic内所有的消息按照先进先出的顺序进行发布和消费

#### 如何保证消息的可靠性传输？或者说，如何处理消息丢失的问题？

rocketMQ：

在发送消息的事情去确认是否发生成功，有一个 SendStatus.SEND_OK的状态确认，如果失败了就重试，连续几次失败的，那可以发邮件通知人工介入去查看原因了。

在消费的时候也会有Ack确认机制，只要当消费端消费成功，才返回CONSUME_SUCCESS的标志，表示这条消息消费了，如果失败了就重新延迟消费

kafka：生成者端有ack确认机制，会确认broker能够接收，broker端有副本机制，会将消费做备份，在消费端，有offset commit，每次消费完提交自己的offset，下次继续消费时会接着上次的offset进行消费。
